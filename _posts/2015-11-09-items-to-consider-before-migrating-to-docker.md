---
layout: post
title:  "Items to consider before migrating to docker"
date:   2015-11-09 22:18:00
categories: devops, programming, functional-programming
comments: true
published: false
---
1. **First consider the exact reasons you adopt `docker`**, or better, in it's generalized form - for adopting `containerized` packaging and deployments methodology.  Believe it or not, it's easy to get mislead by all the rumours spread around.  A good answer for the question, why am I changing my deployment architecture to containerized based deployments would be that you are a developer who appreciates with caution the concept of immutability and `functional-programming`.  In this case `containers` allows you to deploy these concepts into your deployments.  Having `containerized` deployments allows you to have `immutable deployments` in a much easier and fun way.  By having your containers `read-only` you may even come closer to the concept of `pure deployments` where you do no modifications but only replacements.  A mostly bad answer would be because you think it will improve the performance of a certain server.  Having that issue solved let's move on the next items to consider before you take action.  *the game where you push one thing and another one pops out hopefully with one eye out*

2. **Are you ready for immutable deployments?** In the previous item we dealt with the motivation to adopt `docker`.  Lets check how ready you are for this new methodology.  Questions to ask: Do you install your apps from scratch, is that already happening in production? If not - are you at least already deploying your apps into `VM's`, or, even better to `cloud-vm's`?  Do deployment/production team add new instances of your app without contacting the relevant developers team as if they do not exist? If I restart your apps now will all behave as usual (the usual without problems)?  If you answered yes to at least some of the above, then, the effort of moving into containerized deployments is achievable with much less frustration.  If not, you should first review your deployments, update them, or be ready for much more work when using container based deployments.  (Note, if you plan to mutate your environments with containerized based deployments you are heading the wrong way) *put someone with his finger out measuring the air heat*

3. **What are your plans for current deployment tools** In most cases you already use deployment tools such as `puppet`, `rpm` and the like.  On one hand using these tools is great, because this means your deployments are very close to fully automated (or already fully automated).  On the other hand this means you have a choice to make.  Either dump them and use a single container package builder (`Dockerfile`) or else continue using your `rpm` scripts together with `docker` scripts, and same for `puppet` scripts.  Personally I would recommend you to try and get things simple on this matter, if you can have a single scripting language, go for it, if you already have too much infrastructure around `rpm` consider keeping it.  Note that if you continue having the bulk of packaging in `rpm` this would mean you should aspire to being able to install your packages even without `docker`.  As for `puppet` you should highly consider replacing it all together by `docker` scripting an its peripheral scripts (`kubernetes`).  *two dogs running one after another one named puppet and one named kubernetes*

4. **Training** - You would need to train your developers AND QA AND support AND ANY other technical tier which has any access to servers in any env on docker.  Even in cases where you don't plan to use docker in dev/qa (and you should!) they would still need to investigate issues in production, its not going to be a good idea that the troubleshooters won't know the environment on which their servers are running, good understanding that is.  Beside from learning syntaxly how to use docker you have to understand linux containers fundamentals, how docker is implements, how is memory shared in between your containers? disk? cpu? affinity? namespaces? how to access the processes outside of containers? how to read logs from your containers? how to permit developers access log files? there are plenty of items to check here and training, best thought of self training is the best option here.  The best way to achieve that would be to create some training receipes and lets the self training move on by itself.  *someone doing pushups or lifting his laptop up and down when he lies down as if those are mishkolot*

5. **App and deployment types** You must be having many flavours of servers.  You must be having http style servers, but do you have also storm topologies? hadoop jobs? spark? spark streaming? `vert.x`? databases? which flavours? Do you already use `YARN`, `Mesos`? What about spontaneous command run like `tcpdump` do you also consider them as `apps`? (hint: yes).  This means you need to take into consideration a heterogenous production system and see how docker would fit it.  Also as you consider `docker` you probably already consider using `kubernetes` (hint: yes), This has to philarmon all together.  **concert a philharmony all together**.

6. **Tagging Convention** You might have already been tagging your app releases.  By tags we don't mean plain software versions but also meaningful names to your builds.  Docker taken this step up to convention it already holds the notion of tags.  So now you can be officially a software release tagger, and if you wondered in the past whether that was a good enough practice here is an affirmation to that.  But, you ha
 the version control revision where this image was created from, tag can be extremely useful for that, so tag with the info you not to much but not too less, I would not recommend not including for example teh version control revision the image was created from, you really want a super easy way to get to the source code of that build.

7. **Undrift your severs** So you have got everything in you favorite configuration management tool.  Every library is nicely and cozily upgraded and downgraded.  You would still have server drift.  First most of configuration managements do not handle deletion well, this already means you might have deletion drift.  If you ever ever do a manual fix (be it an internal library or patch) you are on the highway to server drift.  If all is managed by your configuration management tool then over time upgrades and downgrades which brings along dependendies and hence subdenencies will cause drift.  Once you start using container based images for deployments you are on the reverse highway to reverse that drift.  But as this is a game changer you should be aware of it.  And utilize it for the best, meaning, before patching anything or upgrading do it though the image, this will keep your servers from drifting.   

Note that as one of the main things we want to get out of docker or any other container is to prevent server drift, if you are already in a state where you are as immutable as you can in your server installations then you are in a good position.  If you are far from it first check how different are your servers one from another (which are supposed to be the same if they are running same app) if they are different then first check if by having them all the same your services are still behaving the same, this will have you much closer to being able to run docker with less issues at first.


2. logging.
3. Tagging labeling docker tag should just be the vesion name or latest registry is global and repository is for the project
3. configuration for minimal configuration like one parameter pass it as argument, for a few more pass them as environment variable, always prefer to have convention for example if you use some cassandra host simply refer to DNS CASSANDRA in dev would be the right one in prod the right one.  For more complex configuration consider storing them in some kind of database or in volume files.
4. monitoring the containers.
5. performance tuning.
6. using linux.
7. already using puppet? rpm? now you are going to have another scripting language docker md.
8. You could even increase security by having a container read only! nothing can write to it.  security audits can be faster all these apps are read only.
9. docker vs swarm vs kuber http://radar.oreilly.com/2015/10/swarm-v-fleet-v-kubernetes-v-mesos.html
10. What about rollout maybe consider the non rolled out services as all kubernetes service which will hide they are not a service its just an abstraction.
11. You can have another container the first one we don't need tcpdump and tcpflow and the other container will include these services which would mean you can listen to its ethernet without introducing security issues.
